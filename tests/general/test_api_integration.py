#!/usr/bin/env python3
"""
Simple API test for the RAG system with Ollama
"""
import requests
import json

def test_api():
    """Test the API endpoints"""
    base_url = "http://localhost:8000"

    print("ğŸ§ª Testing EideticRAG API with Ollama")
    print("=" * 50)

    # Test 1: Health check
    try:
        response = requests.get(f"{base_url}/")
        print("âœ… API Health Check:", response.json())
    except Exception as e:
        print("âŒ API Health Check Failed:", str(e))
        return False

    # Test 2: Stats
    try:
        response = requests.get(f"{base_url}/stats")
        print("âœ… Index Stats:", response.json())
    except Exception as e:
        print("âŒ Index Stats Failed:", str(e))

    # Test 3: Query (this will use Ollama)
    test_query = "What is machine learning?"
    print(f"\nğŸ¤– Testing Query: '{test_query}'")
    print("-" * 30)

    try:
        response = requests.post(
            f"{base_url}/query",
            json={"query": test_query, "k": 3},
            timeout=30  # Give time for Ollama generation
        )

        if response.status_code == 200:
            result = response.json()
            print("âœ… Query Successful!")
            print(f"   Answer: {result['answer'][:200]}...")
            print(f"   Model Used: {result['metadata']['model']}")
            print(f"   Chunks Retrieved: {result['metadata']['num_chunks_retrieved']}")
            print(f"   Processing Time: ~{result['metadata'].get('processing_time', 'N/A')}s")
            return True
        else:
            print(f"âŒ Query Failed: {response.status_code}")
            print(f"   Response: {response.text}")
            return False

    except requests.exceptions.Timeout:
        print("âŒ Query Timeout: Ollama might be processing slowly")
        return False
    except Exception as e:
        print(f"âŒ Query Error: {str(e)}")
        return False

if __name__ == "__main__":
    success = test_api()

    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ Integration Test PASSED!")
        print("\nYour EideticRAG system with Ollama is working perfectly!")
        print("âœ… API server running")
        print("âœ… Ollama integration active")
        print("âœ… RAG pipeline functional")
        print("\nğŸŒ Access the web interface at: http://localhost:3000")
        print("ğŸ“– API documentation at: http://localhost:8000/docs")
    else:
        print("âš ï¸  Some tests failed. Check:")
        print("1. Ollama is running: ollama serve")
        print("2. Model is available: ollama list")
        print("3. API server: python -m uvicorn src.api.main:app --reload")
