# Configuration for SpikingBrain Integration
# Copy this to your .env file to enable SpikingBrain

# Set the generator type to use SpikingBrain
RAG_GENERATOR_TYPE=spikingbrain

# SpikingBrain model configuration
RAG_MODEL_NAME=Panyuqi/V1-7B-sft-s3-reasoning
RAG_DEVICE=cuda  # or "cpu" if no GPU available
RAG_CACHE_DIR=~/.cache/spikingbrain

# Performance tuning
RAG_TEMPERATURE=0.7
RAG_TOP_P=0.9
RAG_MAX_LENGTH=2048

# Web Search Configuration (No API keys needed!)
# DuckDuckGo search is integrated and enabled via frontend toggle
# Supports three strategies: local_only, web_only, hybrid
WEB_SEARCH_MAX_RESULTS=5

# Alternative models (uncomment to use different SpikingBrain variants)
# RAG_MODEL_NAME=Panyuqi/V1-7B-base  # Base pre-trained model
# RAG_MODEL_NAME=Abel2076/SpikingBrain-7B-W8ASpike  # Quantized version

# To switch back to traditional LLMs, use:
# RAG_GENERATOR_TYPE=ollama
# RAG_MODEL_NAME=llama2
